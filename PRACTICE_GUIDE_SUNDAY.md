# üöÄ Gu√≠a Pr√°ctica Domingo
## Fases 6-8: Monitoring Enterprise, Cost Optimization & Troubleshooting

> **Tiempo estimado**: ~5 horas
> **Objetivo**: Operaciones del d√≠a a d√≠a, monitoring enterprise con Prometheus/Grafana, y skills de troubleshooting

---

# üìã Agenda del D√≠a

| Tiempo | Fase | Tema |
|--------|------|------|
| 30min | Prep | Recrear infraestructura |
| 2.5h | 6 | Monitoring Enterprise (Azure Monitor + Prometheus + Grafana) |
| 30min | 7 | Cost Optimization |
| 1.5h | 8 | Troubleshooting Pr√°ctico |

---

# üîÑ PREPARACI√ìN: Recrear Infraestructura (30 min)

```powershell
cd "c:\Users\Daniel Matapi\cloud-practice\azure-voting-app-redis\terraform"

# Si ya tienes remote backend
terraform init
terraform apply -var-file="environments/dev.tfvars" -auto-approve

# Configurar kubectl
az aks get-credentials --resource-group votingapp-dev-rg --name votingapp-dev-aks --overwrite-existing

# Desplegar app con Kustomize
kubectl apply -k k8s/overlays/dev

# Verificar
kubectl get all -n voting-app
```

---

# FASE 6: MONITORING ENTERPRISE (2.5h)

## üéì Conceptos Clave

### Los 4 Golden Signals de Google SRE

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   4 GOLDEN SIGNALS                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  1. LATENCY         ‚Üí ¬øQu√© tan r√°pido responde?            ‚îÇ
‚îÇ     (tiempo de respuesta)                                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  2. TRAFFIC         ‚Üí ¬øCu√°ntas requests recibe?            ‚îÇ
‚îÇ     (requests/segundo)                                      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  3. ERRORS          ‚Üí ¬øCu√°ntas requests fallan?            ‚îÇ
‚îÇ     (tasa de errores %)                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  4. SATURATION      ‚Üí ¬øQu√© tan llenos est√°n los recursos?  ‚îÇ
‚îÇ     (CPU, memoria, disco)                                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack de Monitoring Enterprise

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MONITORING STACK ENTERPRISE                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  CAPA 1: Infraestructura (Azure Monitor)                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Container Insights (ya configurado)                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Log Analytics (KQL queries)                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Azure Alerts                                           ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  CAPA 2: M√©tricas (Prometheus)                              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Scraping de m√©tricas de pods                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Recording rules                                        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ PromQL para queries                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  CAPA 3: Visualizaci√≥n (Grafana)                            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Dashboards unificados                                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Alerting avanzado                                      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Multi-datasource                                       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ¬øPor qu√© Prometheus + Grafana adem√°s de Azure Monitor?

| Herramienta | Fortaleza | Caso de Uso |
|-------------|-----------|-------------|
| **Azure Monitor** | Infraestructura Azure, integraci√≥n nativa | Nodos, cluster health, Azure services |
| **Prometheus** | M√©tricas de aplicaci√≥n, est√°ndar K8s | Custom metrics, pod-level, service mesh |
| **Grafana** | Visualizaci√≥n, multi-source | Dashboards unificados, business metrics |

**En entrevista**: "Usamos Azure Monitor para infraestructura y Prometheus/Grafana para m√©tricas de aplicaci√≥n. Este enfoque multi-herramienta nos da visibilidad completa del stack."

---

## Paso 6.1: Ver M√©tricas en Azure Portal (Container Insights)

```powershell
# Abre el portal directamente en AKS
$RG = "votingapp-dev-rg"
$AKS = "votingapp-dev-aks"

# Obtener la URL del portal
Write-Host "Abre: https://portal.azure.com/#@/resource/subscriptions/$(az account show --query id -o tsv)/resourceGroups/$RG/providers/Microsoft.ContainerService/managedClusters/$AKS/overview"
```

En el portal:
1. Ve a **Insights** en el men√∫ lateral
2. Explora las pesta√±as: **Cluster**, **Nodes**, **Controllers**, **Containers**
3. Ve las m√©tricas de CPU y memoria de tus pods

---

## Paso 6.2: Habilitar Azure Managed Prometheus

### ¬øQu√© es Azure Managed Prometheus?

Servicio totalmente gestionado que:
- Recolecta m√©tricas de Kubernetes autom√°ticamente
- Almacena en Azure Monitor Workspace
- Compatible 100% con PromQL
- Sin necesidad de administrar servidores

```powershell
$RG = "votingapp-dev-rg"
$AKS = "votingapp-dev-aks"

# Crear Azure Monitor Workspace para Prometheus
az monitor account create `
    --name "votingapp-prometheus" `
    --resource-group $RG `
    --location eastus

# Obtener el ID del workspace
$MONITOR_WORKSPACE_ID = az monitor account show `
    --name "votingapp-prometheus" `
    --resource-group $RG `
    --query id -o tsv

# Habilitar Prometheus en AKS
az aks update `
    --name $AKS `
    --resource-group $RG `
    --enable-azure-monitor-metrics `
    --azure-monitor-workspace-resource-id $MONITOR_WORKSPACE_ID

Write-Host "Prometheus habilitado! Espera 2-3 minutos para que empiecen las m√©tricas"
```

### Verificar que Prometheus est√° funcionando

```powershell
# Ver los pods del agente de Prometheus
kubectl get pods -n kube-system | Select-String "ama-metrics"

# Deber√≠as ver algo como:
# ama-metrics-node-xxxxx     Running
# ama-metrics-xxxxx          Running
```

---

## Paso 6.3: Crear Azure Managed Grafana

### ¬øQu√© es Azure Managed Grafana?

- Grafana totalmente gestionado por Azure
- Integraci√≥n autom√°tica con Azure AD (SSO)
- Conecta con Prometheus, Azure Monitor, Log Analytics
- Dashboards pre-configurados para AKS

```powershell
$RG = "votingapp-dev-rg"

# Crear instancia de Grafana (esto toma ~3-5 minutos)
az grafana create `
    --name "votingapp-grafana" `
    --resource-group $RG `
    --location eastus

# Obtener la URL de Grafana
$GRAFANA_URL = az grafana show `
    --name "votingapp-grafana" `
    --resource-group $RG `
    --query "properties.endpoint" -o tsv

Write-Host "Grafana disponible en: $GRAFANA_URL"
```

### Conectar Grafana con Prometheus

```powershell
# Obtener IDs necesarios
$GRAFANA_ID = az grafana show --name "votingapp-grafana" --resource-group $RG --query id -o tsv
$MONITOR_WORKSPACE_ID = az monitor account show --name "votingapp-prometheus" --resource-group $RG --query id -o tsv

# Asignar rol de lector a Grafana sobre Prometheus workspace
az role assignment create `
    --assignee-object-id $(az grafana show --name "votingapp-grafana" --resource-group $RG --query "identity.principalId" -o tsv) `
    --assignee-principal-type ServicePrincipal `
    --role "Monitoring Reader" `
    --scope $MONITOR_WORKSPACE_ID

# Tambi√©n dar acceso a las m√©tricas del AKS
az role assignment create `
    --assignee-object-id $(az grafana show --name "votingapp-grafana" --resource-group $RG --query "identity.principalId" -o tsv) `
    --assignee-principal-type ServicePrincipal `
    --role "Monitoring Reader" `
    --scope $(az aks show -g $RG -n votingapp-dev-aks --query id -o tsv)

Write-Host "Grafana conectado a Prometheus!"
```

---

## Paso 6.4: Explorar Grafana y Crear Dashboard

### Acceder a Grafana

1. Abre la URL de Grafana (la obtuviste arriba)
2. Login autom√°tico con Azure AD
3. Ve a **Dashboards** ‚Üí **Browse**

### Importar Dashboard de Kubernetes

1. En Grafana, ve a **Dashboards** ‚Üí **Import**
2. Ingresa ID: `15760` (Kubernetes Cluster Monitoring)
3. Selecciona el datasource de Prometheus
4. Click **Import**

### Crear Dashboard para VotingApp

1. **Dashboards** ‚Üí **New** ‚Üí **New Dashboard**
2. Add visualization ‚Üí Selecciona Prometheus
3. Queries PromQL para la app:

```promql
# CPU por pod del frontend
rate(container_cpu_usage_seconds_total{namespace="voting-app", pod=~".*frontend.*"}[5m])

# Memoria del frontend
container_memory_working_set_bytes{namespace="voting-app", pod=~".*frontend.*"}

# Requests por segundo (si tienes m√©tricas HTTP)
rate(http_requests_total{namespace="voting-app"}[5m])
```

4. Guarda como "VotingApp Dashboard"

---

## Paso 6.5: Queries PromQL Esenciales

### En Grafana ‚Üí Explore (icono de br√∫jula)

```promql
# CPU total por namespace
sum(rate(container_cpu_usage_seconds_total{namespace="voting-app"}[5m])) by (pod)

# Memoria por container
container_memory_working_set_bytes{namespace="voting-app"} / 1024 / 1024

# Pods en estado Ready
kube_pod_status_ready{namespace="voting-app", condition="true"}

# Restart count (indica problemas)
kube_pod_container_status_restarts_total{namespace="voting-app"}

# Network bytes recibidos
rate(container_network_receive_bytes_total{namespace="voting-app"}[5m])
```

### Comparaci√≥n: PromQL vs KQL

| PromQL (Prometheus) | KQL (Azure Monitor) | Uso |
|---------------------|---------------------|-----|
| `rate(cpu[5m])` | `Perf \| summarize avg(CPU)` | Promedios de CPU |
| `sum by (pod)` | `\| summarize by PodName` | Agrupar por pod |
| `{namespace="x"}` | `\| where Namespace == "x"` | Filtrar |

---

## Paso 6.6: Crear Alerta en Grafana

1. En tu dashboard, edita el panel de CPU
2. Click en **Alert** tab
3. **Create alert rule**:
   - Condition: `WHEN avg() OF query IS ABOVE 0.8`
   - Evaluate every: 1m
   - For: 5m
4. Add notification channel (configura email o Slack)
5. Save

### Tambi√©n en Azure Monitor (ya lo ten√≠as):

```powershell
$RG = "votingapp-dev-rg"
$AKS = "votingapp-dev-aks"

# Crear Action Group
az monitor action-group create `
    --name "votingapp-alerts" `
    --resource-group $RG `
    --short-name "voting" `
    --action email admin tu-email@example.com

# Crear Alerta de CPU
az monitor metrics alert create `
    --name "high-cpu-alert" `
    --resource-group $RG `
    --scopes $(az aks show -g $RG -n $AKS --query id -o tsv) `
    --condition "avg node_cpu_usage_percentage > 80" `
    --window-size 5m `
    --evaluation-frequency 1m `
    --severity 2 `
    --description "CPU del nodo supera 80%"
```

---

## Paso 6.7: Query de Logs con KQL

En Azure Portal ‚Üí Log Analytics Workspace ‚Üí Logs:

```kusto
// Ver logs de los containers del frontend
ContainerLogV2
| where ContainerName == "frontend"
| where TimeGenerated > ago(1h)
| project TimeGenerated, LogMessage, ContainerName
| order by TimeGenerated desc
| take 50
```

```kusto
// Ver pods con alto consumo de memoria
KubePodInventory
| where Namespace == "voting-app"
| join kind=inner (
    Perf
    | where ObjectName == "K8SContainer"
    | where CounterName == "memoryWorkingSetBytes"
    | summarize AvgMemory = avg(CounterValue) by InstanceName
) on $left.ContainerID == $right.InstanceName
| project PodName = Name, AvgMemoryMB = AvgMemory / 1024 / 1024
| order by AvgMemoryMB desc
```

```kusto
// Errores en los √∫ltimos 30 minutos
ContainerLogV2
| where TimeGenerated > ago(30m)
| where LogMessage contains "error" or LogMessage contains "Error" or LogMessage contains "ERROR"
| project TimeGenerated, ContainerName, LogMessage
```

---

## üéì Cu√°ndo usar cada herramienta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           DECISION TREE: QU√â HERRAMIENTA USAR               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ¬øEs m√©trica de infraestructura Azure?                      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ S√ç ‚Üí Azure Monitor                                     ‚îÇ
‚îÇ       (nodos, networking, storage)                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ¬øEs m√©trica de aplicaci√≥n/pods?                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ S√ç ‚Üí Prometheus + Grafana                              ‚îÇ
‚îÇ       (custom metrics, request rates, latency)              ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ¬øNecesitas logs detallados?                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ S√ç ‚Üí Log Analytics + KQL                               ‚îÇ
‚îÇ       (debugging, audit, troubleshooting)                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ¬øDashboard para stakeholders?                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ S√ç ‚Üí Grafana                                           ‚îÇ
‚îÇ       (visualizaci√≥n bonita, multi-source)                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ Checklist Fase 6

- [ ] Explor√© Container Insights en el portal
- [ ] Habilit√© Azure Managed Prometheus
- [ ] Cre√© Azure Managed Grafana
- [ ] Conect√© Grafana con Prometheus
- [ ] Import√© dashboard de Kubernetes
- [ ] Ejecut√© queries PromQL b√°sicas
- [ ] Ejecut√© queries KQL en Log Analytics
- [ ] Cre√© al menos una alerta
- [ ] Entiendo los 4 Golden Signals
- [ ] S√© cu√°ndo usar cada herramienta

---

# FASE 7: FINOPS & COST MANAGEMENT (45 min)

## üéì ¬øQu√© es FinOps?

**FinOps** = Financial Operations para Cloud. Es la pr√°ctica de dar **visibilidad, control y optimizaci√≥n** de costos cloud a toda la organizaci√≥n.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CICLO FINOPS                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ     INFORM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ OPTIMIZE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ OPERATE                ‚îÇ
‚îÇ        ‚îÇ               ‚îÇ               ‚îÇ                    ‚îÇ
‚îÇ        ‚îÇ               ‚îÇ               ‚îÇ                    ‚îÇ
‚îÇ   Visibilidad     Reducir          Gobierno                ‚îÇ
‚îÇ   de costos       desperdicio      continuo                ‚îÇ
‚îÇ        ‚îÇ               ‚îÇ               ‚îÇ                    ‚îÇ
‚îÇ        ‚ñº               ‚ñº               ‚ñº                    ‚îÇ
‚îÇ   - Dashboards    - Right-size     - Budgets               ‚îÇ
‚îÇ   - Reports       - Reserved       - Alertas               ‚îÇ
‚îÇ   - Allocations   - Spot VMs       - Policies              ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéì D√≥nde se gasta dinero en tu setup

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COSTOS DEL PROYECTO                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  GRATIS:                                                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Control plane (AKS)                                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Kubernetes API                                         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ GitHub Actions (2000 min/mes free)                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  PAGADO (orden de impacto):                                 ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üí∞üí∞üí∞ VMs de los nodos (70-80% del costo)            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üí∞üí∞  Azure Managed Grafana (~$90/mes)                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üí∞    Load Balancer (~$20/mes)                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üí∞    Log Analytics (por GB ingestado)                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üí∞    Azure Monitor Workspace (Prometheus)            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üíµ    Storage (discos OS de nodos)                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ üíµ    ACR Basic (~$5/mes)                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Paso 7.1: Azure Cost Management (Portal)

### Navegar al portal

1. Abre: **https://portal.azure.com**
2. Busca: **"Cost Management + Billing"**
3. Click en **"Cost Management"** ‚Üí **"Cost analysis"**

### Explorar Cost Analysis

```
FILTROS IMPORTANTES:
‚îú‚îÄ‚îÄ Scope: Selecciona tu suscripci√≥n o Resource Group
‚îú‚îÄ‚îÄ View: Cambia entre "Accumulated" y "Daily"
‚îú‚îÄ‚îÄ Group by: 
‚îÇ   ‚îú‚îÄ‚îÄ Resource (ver qu√© recursos cuestan m√°s)
‚îÇ   ‚îú‚îÄ‚îÄ Resource type (ver por tipo: VMs, Storage, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ Tag (si usas tags de cost allocation)
‚îÇ   ‚îî‚îÄ‚îÄ Service name (services de Azure)
‚îî‚îÄ‚îÄ Date range: √öltimos 7 d√≠as, este mes, custom
```

### Lo que debes mirar:

1. **Top 5 recursos m√°s caros** - usualmente son VMs
2. **Tendencia diaria** - ¬øhay picos anormales?
3. **Forecast** - Azure predice cu√°nto gastar√°s este mes

---

## Paso 7.2: Crear Budget con Alertas

### Desde el Portal (RECOMENDADO)

1. En Cost Management ‚Üí **Budgets** ‚Üí **+ Add**
2. Configurar:

| Campo | Valor para tu proyecto |
|-------|----------------------|
| Name | `votingapp-dev-budget` |
| Reset period | Monthly |
| Amount | $50 (o lo que consideres razonable) |

3. En **Alert conditions**, agregar:

| % del budget | Acci√≥n |
|--------------|--------|
| 50% | Email de aviso "vas a mitad" |
| 80% | Email de warning "cerca del l√≠mite" |
| 100% | Email urgente + considera auto-shutdown |

4. En **Alert recipients**: tu email

### ¬øPor qu√© es cr√≠tico en enterprise?

```
ESCENARIO REAL:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sin Budget:                                                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Developer deja cluster corriendo el fin de semana      ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Lunes: factura de $500 inesperada üí∏               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Con Budget + Alertas:                                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Viernes 5pm: alerta "80% del budget"                   ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Developer: "ah, debo destruir antes de irme"       ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ Lunes: $0 de sorpresas ‚úÖ                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Paso 7.3: Azure Advisor (Recomendaciones Autom√°ticas)

### Navegar a Advisor

1. En Azure Portal, busca: **"Advisor"**
2. Ve a la pesta√±a **"Cost"**

### Qu√© te puede recomendar:

| Recomendaci√≥n | Explicaci√≥n |
|--------------|-------------|
| **Resize underutilized VMs** | "Tu VM usa 5% CPU, b√°jala de tama√±o" |
| **Buy Reserved Instances** | "Llevas 3 meses con esta VM, compra reserva" |
| **Delete unattached disks** | "Este disco no est√° conectado a nada" |
| **Shutdown unused resources** | "Este recurso no se ha usado en 30 d√≠as" |

### En tu proyecto probablemente ver√°s:

- ‚úÖ Ya usas B-series (burstable) - optimizado
- ‚ö†Ô∏è Posiblemente: "Consider Reserved Instances" (ignorar, es dev)
- ‚ö†Ô∏è Posiblemente: "Delete unattached resources" (limpiar despu√©s)

---

## Paso 7.4: Cost Allocation con Tags

### ¬øQu√© son los Tags de costo?

Etiquetas que agregas a recursos para saber **qui√©n** o **qu√© proyecto** los usa.

### Tags que ya tienes en Terraform:

```hcl
# Ya definidos en tu variables.tf
tags = {
  Project     = "VotingApp"
  Environment = "dev"
  Owner       = "Daniel"
  ManagedBy   = "Terraform"
}
```

### C√≥mo usarlos en Cost Analysis:

1. En Cost Analysis ‚Üí **Group by** ‚Üí **Tag**
2. Selecciona tag: `Project` o `Environment`
3. Ahora ves costos separados por proyecto/ambiente

### En enterprise:

```
EJEMPLO REAL DE TAGS:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Empresa con 50 equipos:                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Tags obligatorios:                                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ CostCenter: "CC-12345" (para contabilidad)             ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Team: "platform-engineering"                           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Project: "customer-portal"                             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Environment: "prod/staging/dev"                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Reportes mensuales:                                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ "El equipo Platform gast√≥ $5,000 este mes"            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ "El proyecto Customer Portal cuesta $2,000/mes"        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ "Tenemos $3,000 en recursos sin tags (¬°investigar!)"  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Paso 7.5: Alertas de Anomal√≠as de Costo

### Configurar Anomaly Alerts

1. En Cost Management ‚Üí **Cost alerts** ‚Üí **+ Add**
2. Tipo: **Anomaly alert**
3. Configurar:
   - Scope: Tu suscripci√≥n
   - Email recipients: tu correo
   
Esto te avisa cuando hay un **gasto inusual** (ej: alguien crea 10 VMs por error).

---

## Paso 7.6: Optimizaciones Enterprise (Conocimiento para Entrevista)

### Matriz de Optimizaci√≥n

| Estrategia | Ahorro | Cu√°ndo usar | Ya implementado |
|------------|--------|-------------|-----------------|
| **B-series (Burstable)** | ~60% | Dev/Test | ‚úÖ Standard_B2s |
| **Cluster Autoscaler** | Variable | Workloads variables | ‚úÖ min:1, max:3 |
| **Spot Instances** | hasta 90% | Workloads tolerantes | ‚¨ú Opcional |
| **Reserved Instances** | hasta 72% | Workloads estables 1-3 a√±os | ‚¨ú No aplica (dev) |
| **Shutdown schedules** | 100% fuera horario | Dev/Test | ‚úÖ destroy manual |
| **Right-sizing** | 20-50% | VMs sobredimensionadas | ‚úÖ kubectl top |

### Spot Instances (Para mencionar en entrevista)

```hcl
# En Terraform - para workloads tolerantes a interrupciones
resource "azurerm_kubernetes_cluster_node_pool" "spot" {
  name                  = "spot"
  kubernetes_cluster_id = azurerm_kubernetes_cluster.aks.id
  vm_size               = "Standard_D2s_v3"
  priority              = "Spot"
  eviction_policy       = "Delete"
  spot_max_price        = -1  # Precio m√°ximo del mercado
  
  node_labels = {
    "kubernetes.azure.com/scalesetpriority" = "spot"
  }
  
  node_taints = [
    "kubernetes.azure.com/scalesetpriority=spot:NoSchedule"
  ]
}
```

**Cu√°ndo usar Spot:**
- Batch jobs
- CI/CD runners
- Dev/Test environments
- Workloads que pueden reiniciarse

**Cu√°ndo NO usar Spot:**
- Bases de datos de producci√≥n
- APIs cr√≠ticas para el negocio
- Workloads stateful

---

## üéì FinOps: Lo que preguntan en entrevista

**P: ¬øC√≥mo gestionas costos en la nube?**
> "Aplico el ciclo FinOps: Inform, Optimize, Operate. Primero visibilidad con Cost Management y tags de allocation por equipo/proyecto. Luego optimizaci√≥n con right-sizing basado en m√©tricas reales, autoscaler para elasticidad, y Reserved Instances para workloads estables. Finalmente gobierno con budgets y alertas para evitar sorpresas."

**P: ¬øC√≥mo evitas sorpresas de facturaci√≥n?**
> "Budgets con alertas al 50%, 80% y 100%. Anomaly alerts para gastos inusuales. Tags obligatorios para que todo recurso tenga due√±o. Y revisi√≥n semanal de Cost Analysis para detectar tendencias."

**P: ¬øCu√°l es la diferencia entre Spot y Reserved Instances?**
> "Spot es capacidad sobrante de Azure con hasta 90% de descuento pero te pueden quitar la VM con 30 segundos de aviso - ideal para batch jobs o dev. Reserved es un compromiso de 1-3 a√±os con hasta 72% de descuento - ideal para workloads predecibles de producci√≥n."

**P: ¬øC√≥mo implementas chargeback/showback?**
> "Usando tags de Cost Allocation. Cada recurso tiene tags de CostCenter, Team y Project. Luego en Cost Analysis agrupo por tag y genero reportes mensuales que muestran cu√°nto gasta cada equipo. Esto crea accountability - cuando un equipo ve su factura, optimiza m√°s."

---

## ‚úÖ Checklist Fase 7

- [ ] Explor√© Cost Analysis en el portal
- [ ] Entiendo los top 5 recursos m√°s caros
- [ ] Cre√© un Budget con alertas (50%, 80%, 100%)
- [ ] Revis√© Azure Advisor para recomendaciones
- [ ] Entiendo c√≥mo funcionan los tags de Cost Allocation
- [ ] S√© explicar la diferencia entre Spot y Reserved
- [ ] Puedo hablar del ciclo FinOps (Inform, Optimize, Operate)

---

# FASE 8: TROUBLESHOOTING PR√ÅCTICO (1.5h)

## üéì El M√©todo de Troubleshooting

```
1. OBSERVE     ‚Üí  kubectl get, describe, logs, Grafana dashboards
2. ANALYZE     ‚Üí  ¬øQu√© est√° mal? ¬øDesde cu√°ndo? ¬øQu√© cambi√≥?
3. HYPOTHESIZE ‚Üí  ¬øQu√© podr√≠a causar esto?
4. TEST        ‚Üí  Probar la hip√≥tesis
5. FIX         ‚Üí  Aplicar la soluci√≥n
6. VERIFY      ‚Üí  Confirmar que funciona + documentar
```

---

## Escenario 1: Pod en CrashLoopBackOff (20 min)

### Simular el problema

```powershell
# Cambia el comando del container a algo que falla
kubectl patch deployment frontend -n voting-app --type='json' -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/command", "value": ["python", "noexiste.py"]}]'

# Espera y observa
kubectl get pods -n voting-app -w
```

### Diagnosticar

```powershell
# Ver estado
kubectl get pods -n voting-app

# Ver detalles del pod
kubectl describe pod -l app=frontend -n voting-app | Select-String -Pattern "State|Reason|Message|Events" -Context 0,5

# Ver logs
kubectl logs -l app=frontend -n voting-app --previous

# Ver en Grafana: dashboard muestra restart count aumentando
```

### Resolver

```powershell
# Revertir el cambio
kubectl rollout undo deployment/frontend -n voting-app

# Verificar
kubectl rollout status deployment/frontend -n voting-app
```

---

## Escenario 2: ImagePullBackOff (20 min)

### Simular el problema

```powershell
# Cambia la imagen a una que no existe
kubectl set image deployment/frontend frontend=votingappdevacr.azurecr.io/noexiste:v999 -n voting-app

# Observa
kubectl get pods -n voting-app -w
```

### Diagnosticar

```powershell
# Ver eventos
kubectl describe pod -l app=frontend -n voting-app | Select-String -Pattern "Events" -Context 0,10

# Respuesta t√≠pica: "Failed to pull image... not found"

# Verificar qu√© im√°genes existen en ACR
az acr repository list --name votingappdevacr
az acr repository show-tags --name votingappdevacr --repository azure-vote-front
```

### Resolver

```powershell
# Revertir a imagen correcta
kubectl rollout undo deployment/frontend -n voting-app
```

---

## Escenario 3: Service sin External IP (15 min)

### Diagnosticar

```powershell
kubectl get svc -n voting-app

# Si EXTERNAL-IP est√° <pending> por mucho tiempo:
kubectl describe svc frontend -n voting-app

# Buscar en Events mensajes como:
# - "Error syncing load balancer"
# - "Quota exceeded"
```

### Causas comunes

| Mensaje | Causa | Soluci√≥n |
|---------|-------|----------|
| "quota exceeded" | L√≠mite de IPs p√∫blicas | Aumentar quota o usar Ingress |
| "subnet full" | Sin IPs disponibles | Expandir subnet |
| Pending forever | NSG bloqueando | Verificar reglas NSG |

---

## Escenario 4: Aplicaci√≥n lenta (20 min)

### Diagnosticar

```powershell
# Ver uso de recursos (CLI)
kubectl top pods -n voting-app
kubectl top nodes

# Ver en Grafana - buscar:
# - CPU cerca del l√≠mite
# - Memoria saturada
# - Throttling

# Si CPU cerca de l√≠mite:
kubectl describe pod -l app=frontend -n voting-app | Select-String "Limits|Requests"

# Ver HPA
kubectl get hpa -n voting-app
```

### Resolver

```powershell
# Aumentar recursos temporalmente
kubectl patch deployment frontend -n voting-app -p '{"spec":{"template":{"spec":{"containers":[{"name":"frontend","resources":{"limits":{"cpu":"1000m"}}}]}}}}'

# O forzar scaling manual
kubectl scale deployment frontend --replicas=3 -n voting-app
```

---

## Escenario 5: No conecta a Redis (15 min)

### Diagnosticar

```powershell
# Ver logs del frontend
kubectl logs -l app=frontend -n voting-app | Select-String "redis|Redis|connection"

# Verificar que Redis est√° corriendo
kubectl get pods -l app=redis -n voting-app

# Verificar el Service de Redis
kubectl get svc redis -n voting-app
kubectl describe svc redis -n voting-app

# Test de conectividad desde frontend
kubectl exec -it $(kubectl get pod -l app=frontend -n voting-app -o jsonpath='{.items[0].metadata.name}') -n voting-app -- python -c "import redis; r = redis.Redis('redis'); print(r.ping())"
```

### Causas comunes

| S√≠ntoma | Causa | Soluci√≥n |
|---------|-------|----------|
| Connection refused | Redis no est√° corriendo | Verificar deployment de Redis |
| Name resolution failed | Service no existe | Crear/verificar Service |
| Connection timeout | NetworkPolicy bloqueando | Verificar/ajustar NetworkPolicy |

---

## üìã Comandos de Troubleshooting Esenciales

```bash
# Estado general
kubectl get all -n voting-app
kubectl get events -n voting-app --sort-by='.lastTimestamp'

# Pods problem√°ticos
kubectl get pods -n voting-app -o wide
kubectl describe pod <pod-name> -n voting-app
kubectl logs <pod-name> -n voting-app
kubectl logs <pod-name> -n voting-app --previous  # Si crashe√≥

# Recursos
kubectl top pods -n voting-app
kubectl top nodes

# Exec into pod (debug)
kubectl exec -it <pod-name> -n voting-app -- /bin/sh

# Rollback
kubectl rollout undo deployment/<name> -n voting-app
kubectl rollout history deployment/<name> -n voting-app

# Network debug
kubectl run debug --rm -it --image=busybox -n voting-app -- /bin/sh
# Dentro: nslookup redis, wget -qO- http://frontend:80/
```

---

## ‚úÖ Checklist Fase 8

> **NOTA**: Si ya resolviste problemas reales durante la pr√°ctica, consulta [TROUBLESHOOTING_REAL.md](docs/TROUBLESHOOTING_REAL.md) - eso tiene m√°s valor que escenarios simulados.

- [ ] Practiqu√© CrashLoopBackOff y s√© c√≥mo diagnosticarlo
- [ ] Practiqu√© ImagePullBackOff y s√© la causa com√∫n
- [ ] Entiendo c√≥mo diagnosticar problemas de Service
- [ ] S√© usar kubectl top, describe, logs, exec
- [ ] Us√© Grafana para correlacionar m√©tricas con problemas
- [ ] Puedo hacer rollback de un deployment

---

# üí° Al Terminar Domingo

```powershell
# Destruir todo para evitar costos
cd "c:\Users\Daniel Matapi\cloud-practice\azure-voting-app-redis\terraform"
terraform destroy -auto-approve

# Eliminar recursos de monitoring manual (si creaste aparte)
az grafana delete --name votingapp-grafana --resource-group votingapp-dev-rg --yes
az monitor account delete --name votingapp-prometheus --resource-group votingapp-dev-rg --yes

# Tambi√©n el resource group del tfstate (opcional, si no lo usar√°s m√°s)
# az group delete --name tfstate-rg --yes
```

---

# üé§ Preguntas de Entrevista - Operations & Monitoring

## Monitoring

**P: ¬øQu√© stack de monitoring usas para Kubernetes?**
> "Uso un enfoque de m√∫ltiples capas: Azure Monitor para infraestructura del cluster, Prometheus para m√©tricas de aplicaci√≥n y pods, y Grafana para visualizaci√≥n unificada. Prometheus con PromQL me da flexibilidad para queries complejas, mientras que Azure Monitor me da integraci√≥n nativa con alertas y el ecosistema Azure."

**P: ¬øPor qu√© usar Prometheus si ya tienes Azure Monitor?**
> "Son complementarios. Azure Monitor es excelente para m√©tricas de infraestructura y tiene integraci√≥n nativa con alerting. Pero Prometheus es el est√°ndar de facto en Kubernetes - tiene mejor granularidad para m√©tricas de aplicaci√≥n, service discovery autom√°tico, y PromQL es m√°s poderoso para agregaciones complejas. Adem√°s, si migras a otro cloud, Prometheus es portable."

**P: ¬øCu√°les son los 4 Golden Signals?**
> "Latency, Traffic, Errors, y Saturation. Son las m√©tricas clave que todo sistema deber√≠a monitorear seg√∫n Google SRE. Latency es tiempo de respuesta, Traffic es throughput, Errors es tasa de fallos, y Saturation es qu√© tan cerca estamos de los l√≠mites de recursos."

## Troubleshooting

**P: ¬øC√≥mo diagnosticas un pod en CrashLoopBackOff?**
> "Primero kubectl describe pod para ver eventos y el exit code. Luego kubectl logs --previous para ver qu√© pas√≥ antes del crash. Tambi√©n reviso Grafana donde puedo ver el restart count aumentando y correlacionar con m√©tricas de recursos. Causas comunes: la app falla al iniciar por config incorrecta, falta una variable de entorno, o el probe falla. Puedo hacer rollback r√°pido con kubectl rollout undo."

**P: Un cliente reporta que la app est√° lenta. ¬øQu√© haces?**
> "Primero verifico los 4 Golden Signals en Grafana - latency, error rate, traffic. Luego kubectl top pods para ver consumo de recursos. En Grafana puedo ver si hay CPU throttling. Verifico el HPA - si est√° al m√°ximo de r√©plicas, puede ser un problema de capacidad. Tambi√©n reviso latencia hacia Redis en los logs. El enfoque es siempre: observe, analyze, hypothesize, test, fix, verify."

## Cost Optimization

**P: ¬øC√≥mo optimizas costos en AKS?**
> "Varias estrategias: B-series VMs para dev que son burstable y ~60% m√°s baratas. Cluster autoscaler para escalar nodos basado en demanda real. Spot instances para workloads tolerantes a interrupciones - hasta 90% de ahorro. Reserved instances para workloads predecibles. Right-sizing basado en kubectl top y m√©tricas de Prometheus. Y siempre destruir recursos dev/staging cuando no se usan - terraform destroy al final del d√≠a."

---

# üîë Keywords para Entrevista

## Monitoring
- Prometheus, PromQL, Service Discovery, Scraping
- Grafana, Dashboards, Alerting, Visualization
- Azure Monitor, Container Insights, Log Analytics
- KQL (Kusto Query Language)
- 4 Golden Signals (Latency, Traffic, Errors, Saturation)
- Observability (Metrics, Logs, Traces)
- Multi-tool monitoring strategy

## Cost / FinOps
- FinOps (Inform, Optimize, Operate)
- Budgets, Cost Alerts, Anomaly Detection
- Cost Allocation Tags, Showback, Chargeback
- Azure Advisor, Cost Analysis
- Spot Instances, Reserved Instances
- Right-sizing, Cluster Autoscaler
- B-series (burstable), D-series (dedicated)

## Troubleshooting
- CrashLoopBackOff, ImagePullBackOff
- kubectl describe, logs, exec, top
- Rollback, Rollout
- Root Cause Analysis (RCA)

---

# üìã Resumen: Plan Lunes y Martes

**Lunes:**
- Leer las consolidaciones (PHASE1-5, COMPLETE_RECAP)
- Repasar las preguntas de entrevista de cada fase
- Practicar explicar Prometheus vs Azure Monitor verbalmente

**Martes:**
- Simulaci√≥n de entrevista (pide a alguien que te pregunte)
- Repaso de comandos clave (terraform, docker, kubectl, promql)
- Descansar bien para el mi√©rcoles

¬°√âxito en la entrevista! üöÄ
