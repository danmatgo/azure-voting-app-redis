# ğŸ§  GUÃA MAESTRA - PARTE 4
## Kustomize, CI/CD y DevSecOps

---

# ğŸ“ KUSTOMIZE - MANEJANDO AMBIENTES

## El Problema

Tienes manifests de Kubernetes que funcionan en desarrollo. Pero producciÃ³n necesita:
- MÃ¡s rÃ©plicas (no 2, sino 5)
- MÃ¡s recursos (mÃ¡s CPU/memoria)
- Diferentes configuraciones
- Diferentes imÃ¡genes

**SoluciÃ³n tradicional**: Copiar todos los archivos y modificarlos.

```
k8s-dev/
â”œâ”€â”€ deployment.yaml    (100 lÃ­neas)
â”œâ”€â”€ service.yaml
â””â”€â”€ ...

k8s-prod/
â”œâ”€â”€ deployment.yaml    (100 lÃ­neas, 5 diferencias)
â”œâ”€â”€ service.yaml
â””â”€â”€ ...

Problema: Cambias algo base â†’ tienes que cambiar en AMBOS lugares
```

## La SoluciÃ³n: Kustomize

Kustomize permite definir una BASE y OVERLAYS que solo contienen las diferencias.

```
k8s/
â”œâ”€â”€ base/                    # Lo compartido (90% del cÃ³digo)
â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ overlays/
    â”œâ”€â”€ dev/                 # Solo diferencias para dev
    â”‚   â””â”€â”€ kustomization.yaml (10 lÃ­neas)
    â”‚
    â””â”€â”€ prod/                # Solo diferencias para prod
        â””â”€â”€ kustomization.yaml (10 lÃ­neas)
```

## CÃ³mo Funciona

### base/kustomization.yaml

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: voting-app
resources:
  - namespace.yaml
  - configmap.yaml
  - deployment.yaml
  - service.yaml
  - hpa.yaml
  - pdb.yaml
  - network-policies.yaml
```

**Â¿QuÃ© hace?**: Lista todos los recursos que componen esta aplicaciÃ³n.

`resources`: Archivos YAML a incluir.

### overlays/dev/kustomization.yaml

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ../../base
patches:
  - target:
      kind: Deployment
      name: frontend
    patch: |-
      - op: replace
        path: /spec/replicas
        value: 1
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/cpu
        value: 50m
```

**`resources: - ../../base`**: Incluir TODO de la carpeta base.

**`patches`**: Modificaciones a aplicar encima.

**Partes del patch**:
- `target`: Â¿QuÃ© recurso modificar? (Deployment llamado "frontend")
- `patch`: Â¿QuÃ© cambios hacer?
  - `op: replace`: Reemplazar un valor
  - `path`: UbicaciÃ³n del valor (en formato JSON Pointer)
  - `value`: El nuevo valor

**Â¿QuÃ© significa `/spec/replicas`?**

Es un JSON Pointer. Navega el YAML:
```yaml
spec:           # /spec
  replicas: 2   # /spec/replicas
```

**Â¿Y `/spec/template/spec/containers/0/resources/requests/cpu`?**

```yaml
spec:
  template:
    spec:
      containers:
        - name: frontend      # [0] = primer elemento
          resources:
            requests:
              cpu: 100m       # Este valor
```

## Usando Kustomize

```bash
# Ver quÃ© generarÃ­a (sin aplicar)
kubectl kustomize k8s/overlays/dev

# Aplicar directamente
kubectl apply -k k8s/overlays/dev

# En un pipeline CI/CD
cd k8s/overlays/dev
kustomize edit set image VIEJA_IMAGEN=NUEVA_IMAGEN
kubectl apply -k .
```

**`kustomize edit set image`**: Cambia la imagen sin editar archivos manualmente.

---

# ğŸ”„ CI/CD - AUTOMATIZACIÃ“N

## Â¿QuÃ© problema resuelve?

**Sin CI/CD**:
1. Developer hace commit
2. Developer se conecta al servidor
3. Developer ejecuta manualmente: build, test, deploy
4. Si hay error, volver a empezar
5. Tiempo: horas. Errores: frecuentes.

**Con CI/CD**:
1. Developer hace commit
2. Sistema automÃ¡ticamente: build, test, scan, deploy
3. Developer recibe notificaciÃ³n del resultado
4. Tiempo: minutos. Errores: detectados temprano.

## Los conceptos

**CI (Continuous Integration)**:
- Cada commit se construye y se testea automÃ¡ticamente
- Feedback rÃ¡pido: "tu cÃ³digo rompiÃ³ algo"
- Merge frecuente a la rama principal

**CD (Continuous Delivery/Deployment)**:
- Delivery: Artefacto listo para deploy con un click
- Deployment: Deploy automÃ¡tico a producciÃ³n

## GitHub Actions

GitHub Actions ejecuta "workflows" cuando ocurren eventos.

### AnatomÃ­a de un Workflow

```yaml
name: CI/CD Pipeline
```
**`name`**: Nombre que aparece en la UI de GitHub.

```yaml
on:
  push:
    branches: [master]
    paths: ['azure-vote/**', 'k8s/**']
  pull_request:
    branches: [master]
  workflow_dispatch:
```

**`on`**: Â¿CuÃ¡ndo ejecutar este workflow?

- `push: branches: [master]`: Cuando hay push a master
- `paths`: SOLO si cambiaron archivos en estas carpetas
- `pull_request`: Cuando crean o actualizan un PR
- `workflow_dispatch`: BotÃ³n manual en GitHub

**Â¿Por quÃ© `paths`?**: Si solo cambiÃ³ el README, no tiene sentido hacer build y deploy.

```yaml
env:
  ACR_NAME: votingappdevacr
  ACR_LOGIN_SERVER: votingappdevacr.azurecr.io
  IMAGE_NAME: azure-vote-front
```

**`env`**: Variables de entorno disponibles en todo el workflow.

Definirlas aquÃ­ evita repetir valores en mÃºltiples lugares.

```yaml
permissions:
  id-token: write
  contents: read
```

**`permissions`**: QuÃ© permisos tiene el workflow.

- `id-token: write`: Necesario para OIDC con Azure (explicado abajo)
- `contents: read`: Puede leer el cÃ³digo del repo

```yaml
jobs:
  build:
    name: Build & Scan
    runs-on: ubuntu-latest
```

**`jobs`**: Las tareas a ejecutar. Cada job corre en una mÃ¡quina separada.

**`runs-on`**: En quÃ© sistema operativo correr. `ubuntu-latest` es el mÃ¡s comÃºn.

---

## OIDC - AutenticaciÃ³n sin secretos

### El problema con secretos tradicionales

```
Proceso tradicional:
1. Crear Service Principal en Azure
2. Copiar password
3. Guardar en GitHub Secrets
4. Workflow usa el password

Problemas:
â”œâ”€â”€ Password almacenado en 2 lugares (Azure, GitHub)
â”œâ”€â”€ Password puede expirar
â”œâ”€â”€ Si GitHub se compromete â†’ password expuesto
â””â”€â”€ Hay que rotar manualmente
```

### La soluciÃ³n: OIDC (OpenID Connect)

```
Proceso OIDC:
1. Crear App Registration en Azure
2. Configurar "Federated Credential":
   "ConfÃ­o en tokens de GitHub Actions para repo X, branch Y"
3. Workflow pide un token a GitHub
4. Workflow presenta token a Azure
5. Azure verifica el token y da acceso temporal (15 min)

Beneficios:
â”œâ”€â”€ NO hay password almacenado en GitHub
â”œâ”€â”€ Tokens duran 15 minutos (blast radius limitado)
â”œâ”€â”€ Si GitHub se compromete â†’ tokens expiran automÃ¡ticamente
â””â”€â”€ Zero secret management
```

### Â¿CÃ³mo funciona paso a paso?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions â”‚                     â”‚    Azure AD     â”‚
â”‚                 â”‚                     â”‚                 â”‚
â”‚  1. Necesito    â”‚                     â”‚                 â”‚
â”‚     acceso a    â”‚                     â”‚                 â”‚
â”‚     Azure       â”‚                     â”‚                 â”‚
â”‚        â”‚        â”‚                     â”‚                 â”‚
â”‚        â–¼        â”‚                     â”‚                 â”‚
â”‚  2. Pido token  â”‚                     â”‚                 â”‚
â”‚     a GitHub    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚                 â”‚
â”‚     OIDC        â”‚    3. GitHub       â”‚                 â”‚
â”‚                 â”‚       genera JWT   â”‚                 â”‚
â”‚                 â”‚                     â”‚                 â”‚
â”‚  4. Presento    â”‚                     â”‚                 â”‚
â”‚     token a     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  5. Azure       â”‚
â”‚     Azure       â”‚                     â”‚     verifica:   â”‚
â”‚                 â”‚                     â”‚     - Firma     â”‚
â”‚                 â”‚                     â”‚     - Repo      â”‚
â”‚                 â”‚                     â”‚     - Branch    â”‚
â”‚                 â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚
â”‚  6. Recibo      â”‚    5. OK, aquÃ­    â”‚                 â”‚
â”‚     token       â”‚       tienes      â”‚                 â”‚
â”‚     Azure       â”‚       token       â”‚                 â”‚
â”‚     temporal    â”‚                     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraciÃ³n en el workflow

```yaml
- name: Azure Login (OIDC)
  uses: azure/login@v2
  with:
    client-id: ${{ secrets.AZURE_CLIENT_ID }}
    tenant-id: ${{ secrets.AZURE_TENANT_ID }}
    subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
```

**Â¿QuÃ© son estos IDs?**

- `client-id`: Identificador de la App Registration (pÃºblica, no secreta)
- `tenant-id`: Identificador del directorio de Azure AD (pÃºblica)
- `subscription-id`: La suscripciÃ³n de Azure a usar (pÃºblica)

**NINGUNO es secreto.** Solo identifican quÃ© cuenta usar. La autenticaciÃ³n real es por OIDC.

---

## El Job de Build

```yaml
steps:
  - uses: actions/checkout@v4
```
**Â¿QuÃ© hace?**: Descarga el cÃ³digo del repo a la mÃ¡quina del runner.

Sin esto, el runner estÃ¡ vacÃ­o.

```yaml
  - name: Set image tag
    id: meta
    run: |
      SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
      echo "tag=${{ env.ACR_LOGIN_SERVER }}/${{ env.IMAGE_NAME }}:${SHORT_SHA}" >> $GITHUB_OUTPUT
```

**Â¿QuÃ© hace?**: Crea un tag Ãºnico para la imagen.

**`${{ github.sha }}`**: El hash del commit (ej: `abc123def456...`)

**`cut -c1-7`**: Tomar los primeros 7 caracteres â†’ `abc123d`

**Resultado**: `votingappdevacr.azurecr.io/azure-vote-front:abc123d`

**Â¿Por quÃ© SHA y no `latest`?**

- `latest` â†’ Â¿QuÃ© versiÃ³n es? No sabes sin investigar.
- `abc123d` â†’ Exactamente sabes quÃ© commit es.

Si hay un bug en producciÃ³n, puedes ver quÃ© commit se deployÃ³ y quÃ© cambiÃ³.

```yaml
  - uses: docker/setup-buildx-action@v3
```
**Â¿QuÃ© hace?**: Instala BuildX, una versiÃ³n avanzada de `docker build`.

Beneficios: Multi-platform builds, mejor caching.

```yaml
  - name: Build Docker image
    uses: docker/build-push-action@v5
    with:
      context: ./azure-vote
      push: false
      load: true
      tags: ${{ steps.meta.outputs.tag }}
```

**`context`**: Carpeta desde donde se hace el build (donde estÃ¡ el Dockerfile).

**`push: false`**: NO enviar al registry todavÃ­a.

**`load: true`**: Cargar la imagen localmente (para escanearla).

**Â¿Por quÃ© no pushear inmediatamente?**

```
Build â†’ Push â†’ Scan encuentra vulnerabilidad â†’ Ya estÃ¡ en el registry ğŸ˜±

vs

Build â†’ Scan â†’ (si OK) â†’ Push âœ…
```

Escanear ANTES de pushear es mÃ¡s seguro.

---

## El Job de Deploy

```yaml
deploy:
  name: Deploy to AKS
  needs: build
  runs-on: ubuntu-latest
  if: github.ref == 'refs/heads/master' && github.event_name == 'push'
```

**`needs: build`**: Esperar a que el job `build` termine exitosamente.

**`if`**: SOLO ejecutar si:
- Es la rama master
- Es un push (no un PR)

En PRs solo queremos build+test, no deploy.

```yaml
  - name: Setup Kubeconfig
    run: |
      mkdir -p $HOME/.kube
      echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
      chmod 600 $HOME/.kube/config
```

**Â¿QuÃ© es kubeconfig?**

El archivo que dice cÃ³mo conectarse a Kubernetes:
- URL del cluster
- Certificados de autenticaciÃ³n
- Contextos (si manejas mÃºltiples clusters)

**Â¿Por quÃ© base64?**

GitHub Secrets no maneja bien archivos con caracteres especiales. Se codifica en base64 para almacenarlo como texto plano.

**`chmod 600`**: Solo el dueÃ±o puede leer/escribir. Kubernetes requiere esto por seguridad.

```yaml
  - name: Deploy with Kustomize
    run: |
      cd k8s/overlays/dev
      kustomize edit set image ${{ env.ACR_LOGIN_SERVER }}/${{ env.IMAGE_NAME }}=${{ needs.build.outputs.image-tag }}
      kubectl apply -k .
```

**`needs.build.outputs.image-tag`**: Obtener el tag que generÃ³ el job de build.

**Flujo**:
1. Ir a la carpeta del overlay de dev
2. Actualizar la imagen al nuevo tag
3. Aplicar todos los manifests

```yaml
  - name: Verify deployment
    run: |
      kubectl rollout status deployment/frontend -n voting-app --timeout=120s
```

**Â¿QuÃ© hace `rollout status`?**

Espera a que el Deployment termine de actualizar:
- Nuevos pods creados
- Viejos pods eliminados
- Todos los pods healthy

Si en 120 segundos no termina â†’ falla el pipeline.

---

# ğŸ”’ DEVSECOPS - SEGURIDAD INTEGRADA

## La filosofÃ­a: Shift-Left

```
ANTES (seguridad al final):
CÃ³digo â†’ Build â†’ Test â†’ Deploy â†’ ProducciÃ³n â†’ SCAN â†’ Â¡Problemas!
                                                      â†“
                                              Rollback, pÃ¡nico

AHORA (shift-left):
       SCAN    SCAN    SCAN    SCAN
         â†“       â†“       â†“       â†“
CÃ³digo â†’ Build â†’ Test â†’ Stage â†’ ProducciÃ³n
         â†‘
    Detectar temprano = Arreglar barato
```

**Â¿Por quÃ© se llama "shift-left"?**

En un diagrama de tiempo, la seguridad se "mueve a la izquierda" (mÃ¡s temprano en el proceso).

---

## Trivy - Escaneo de Contenedores

### Â¿QuÃ© es?

Trivy escanea imÃ¡genes Docker buscando:
- **CVEs**: Vulnerabilidades conocidas en paquetes del SO
- **Vulnerabilidades en librerÃ­as**: Flask, Redis, etc.
- **Misconfigurations**: Dockerfile inseguros

### En el workflow

```yaml
- name: Trivy vulnerability scan
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: ${{ steps.meta.outputs.tag }}
    format: 'table'
    exit-code: '0'
    severity: 'CRITICAL,HIGH'
```

**`image-ref`**: QuÃ© imagen escanear.

**`format: table`**: Resultado como tabla legible (hay opciones como JSON, SARIF).

**`exit-code: '0'`**: NO fallar el pipeline aunque encuentre vulnerabilidades.

**`severity: 'CRITICAL,HIGH'`**: Solo reportar vulnerabilidades crÃ­ticas y altas.

### Â¿Por quÃ© exit-code 0?

A veces hay vulnerabilidades en el sistema operativo base (Debian, Alpine) que:
1. No tienen parche disponible
2. No son explotables en tu contexto

Bloquear el pipeline no soluciona el problema. Mejor:
1. Reportar la vulnerabilidad
2. Documentar la decisiÃ³n de riesgo
3. Crear ticket para dar seguimiento

**En producciÃ³n real**:
- `exit-code: 1` para fallar en CRITICAL
- Lista de CVEs ignorados con justificaciÃ³n
- Proceso de revisiÃ³n cuando hay nuevas vulnerabilidades

---

## Dependabot - Actualizaciones automÃ¡ticas

### Â¿QuÃ© es?

Un bot de GitHub que:
1. Revisa quÃ© dependencias tienes
2. Ve si hay versiones nuevas
3. Crea PRs automÃ¡ticamente con las actualizaciones

### ConfiguraciÃ³n

```yaml
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "pip"
    directory: "/azure-vote/azure-vote"
    schedule:
      interval: "weekly"
    labels: ["dependencies", "python"]

  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"

  - package-ecosystem: "docker"
    directory: "/azure-vote"
    schedule:
      interval: "weekly"
```

**`package-ecosystem`**: QuÃ© tipo de dependencias revisar.
- `pip`: requirements.txt de Python
- `github-actions`: Actions usados en workflows
- `docker`: ImÃ¡genes base en Dockerfile

**`directory`**: DÃ³nde buscar el archivo de dependencias.

**`schedule: weekly`**: Revisar una vez por semana.

### Â¿CÃ³mo funciona?

```
Lunes temprano:
â”œâ”€â”€ Dependabot: "Flask 2.3.3 tiene CVE, hay 2.3.4 disponible"
â”œâ”€â”€ Crea PR: "Bump Flask from 2.3.3 to 2.3.4"
â”œâ”€â”€ Pipeline corre tests automÃ¡ticamente
â””â”€â”€ Si tests pasan, puedes hacer merge

vs

Sin Dependabot:
â”œâ”€â”€ Meses despuÃ©s te enteras del CVE
â”œâ”€â”€ Para entonces usas 10 librerÃ­as desactualizadas
â””â”€â”€ Actualizar todo junto es arriesgado
```

---

## CodeQL - AnÃ¡lisis estÃ¡tico

### Â¿QuÃ© es?

Un analyzer de cÃ³digo que busca patrones de vulnerabilidades SIN ejecutar el cÃ³digo.

### Â¿QuÃ© detecta?

- **SQL Injection**: Usuario puede inyectar SQL malicioso
- **XSS**: Usuario puede inyectar JavaScript
- **Command Injection**: Usuario puede ejecutar comandos del sistema
- **Path Traversal**: Usuario puede acceder a archivos del sistema
- **Hardcoded secrets**: Passwords en el cÃ³digo

### ConfiguraciÃ³n

```yaml
name: CodeQL

on:
  push:
    branches: [master]
    paths: ['**.py']
  schedule:
    - cron: '0 6 * * 1'

jobs:
  analyze:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
    steps:
      - uses: actions/checkout@v4
      - uses: github/codeql-action/init@v3
        with:
          languages: python
      - uses: github/codeql-action/autobuild@v3
      - uses: github/codeql-action/analyze@v3
```

**`paths: ['**.py']`**: Solo correr si cambian archivos Python.

**`schedule: cron`**: TambiÃ©n correr cada Lunes a las 6am, para detectar nuevos patrones.

**`security-events: write`**: Permiso para crear Security Alerts en GitHub.

---

## Network Policies - Seguridad en Kubernetes

### El problema

Por defecto, cualquier Pod puede hablar con cualquier otro Pod.

```
SIN NETWORK POLICIES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KUBERNETES                 â”‚
â”‚                                     â”‚
â”‚  Frontend â”€â”€â”€â”€â–¶ Redis    âœ…        â”‚
â”‚  Attacker â”€â”€â”€â”€â–¶ Redis    âœ… ğŸ˜±     â”‚
â”‚  Attacker â”€â”€â”€â”€â–¶ API      âœ… ğŸ˜±     â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### La soluciÃ³n

Network Policies = Firewall a nivel de Pods.

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-allow-frontend-only
  namespace: voting-app
spec:
  podSelector:
    matchLabels:
      app: redis
  policyTypes: [Ingress]
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app: frontend
      ports:
        - port: 6379
```

**Â¿QuÃ© dice esto?**

1. Para pods con label `app: redis`
2. Solo permitir trÃ¡fico ENTRANTE (Ingress)
3. Solo desde pods con label `app: frontend`
4. Solo al puerto 6379

**Resultado**:
```
CON NETWORK POLICIES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KUBERNETES                 â”‚
â”‚                                     â”‚
â”‚  Frontend â”€â”€â”€â”€â–¶ Redis    âœ…        â”‚
â”‚  Attacker â”€â”€â”€â”€â–¶ Redis    âŒ ğŸ”’     â”‚
â”‚  Attacker â”€â”€â”€â”€â–¶ API      âŒ ğŸ”’     â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿Por quÃ© Calico?

Network Policies son un estÃ¡ndar de Kubernetes, pero necesitas un CNI plugin que las implemente.

- **Azure CNI bÃ¡sico**: NO soporta Network Policies
- **Calico**: Soporta Network Policies y mÃ¡s (global policies, etc.)

Por eso en Terraform configuramos:
```hcl
network_policy = "calico"
```
