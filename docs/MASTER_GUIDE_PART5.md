# ğŸ§  GUÃA MAESTRA - PARTE 5
## Problemas encontrados, soluciones, y cÃ³mo explicarlo todo

---

# ğŸ”§ PROBLEMAS Y SOLUCIONES

Esta secciÃ³n documenta todos los problemas que encontramos y cÃ³mo los resolvimos. Esto es EXACTAMENTE lo que te van a preguntar en entrevistas: "CuÃ©ntame un problema tÃ©cnico que hayas enfrentado y cÃ³mo lo resolviste."

---

## Problema 1: Sin permisos para crear App Registration

### SituaciÃ³n

QuerÃ­amos configurar OIDC para que GitHub Actions se autentique con Azure sin passwords. Pero OIDC requiere crear una App Registration en Entra ID (Azure AD).

### El error

```
az ad app create --display-name "github-actions-votingapp"
ERROR: Insufficient privileges to complete the operation.
```

### Â¿Por quÃ© pasÃ³?

En organizaciones empresariales, crear App Registrations estÃ¡ restringido. Necesitas roles como:
- Application Administrator
- Cloud Application Administrator
- Global Administrator

La cuenta de trabajo no tenÃ­a ninguno de estos roles.

### CÃ³mo lo resolvimos

Usamos una arquitectura **cross-account**:

```
CUENTA PERSONAL (Trial con Global Admin)     CUENTA TRABAJO
â”œâ”€â”€ App Registration + OIDC                   â””â”€â”€ AKS Cluster
â”œâ”€â”€ Azure Container Registry (ACR)
â””â”€â”€ Terraform state storage

GITHUB ACTIONS:
â”œâ”€â”€ OIDC â†’ Cuenta Personal â†’ ACR (push imÃ¡genes)
â””â”€â”€ Kubeconfig secret â†’ Cuenta Trabajo â†’ AKS (deploy)
```

**Â¿QuÃ© aprendimos?**

En empresas reales esto es comÃºn. Diferentes equipos manejan diferentes recursos:
- Equipo de Identidad â†’ maneja App Registrations
- Equipo de Plataforma â†’ maneja AKS
- Equipo de Dev â†’ usa ambos

La soluciÃ³n es coordinar con los equipos o usar cuentas de servicio con permisos adecuados.

---

## Problema 2: Trivy bloqueando el pipeline

### SituaciÃ³n

Configuramos Trivy para escanear imÃ¡genes antes de push. Queremos detectar vulnerabilidades.

### El error

```
CRITICAL: libssl3 CVE-2024-XXXX (no fix available)
CRITICAL: openssl CVE-2024-YYYY (no fix available)

Pipeline: FAILED âŒ
```

### Â¿Por quÃ© pasÃ³?

La imagen base (`python:3.11-slim`, basada en Debian) tiene vulnerabilidades en librerÃ­as del sistema operativo. PERO no hay parche disponible todavÃ­a.

### El dilema

```
OpciÃ³n A: Bloquear hasta que haya parche
          â†’ PodrÃ­an pasar semanas/meses
          â†’ No puedes deployar features nuevos

OpciÃ³n B: Ignorar y pushear
          â†’ Vulnerabilidad potencial en producciÃ³n
          â†’ Si hay exploit, es tu responsabilidad
```

### CÃ³mo lo resolvimos

Configuramos Trivy para **reportar sin bloquear**:

```yaml
- name: Trivy scan
  uses: aquasecurity/trivy-action@master
  with:
    exit-code: '0'          # No fallar
    severity: 'CRITICAL,HIGH'
```

Y documentamos la decisiÃ³n:

```
# DecisiÃ³n de Riesgo: CVE-2024-XXXX
Fecha: 2026-01-31
Severidad: CRITICAL
Afecta: libssl3 en Debian Bookworm
Fix disponible: NO
DecisiÃ³n: Aceptar riesgo temporal
JustificaciÃ³n: 
  - No hay parche disponible
  - La vulnerabilidad requiere acceso local
  - Nuestros pods tienen Network Policies
  - Monitorearemos para parchear cuando estÃ© disponible
PrÃ³xima revisiÃ³n: 2026-02-15
```

**Â¿QuÃ© aprendimos?**

La seguridad no es blanco o negro. A veces hay que balancear:
- Riesgo de la vulnerabilidad
- Impacto de no deployar
- Contexto (Â¿es explotable en TU ambiente?)

Lo importante es **documentar la decisiÃ³n** y **dar seguimiento**.

---

## Problema 3: La rama se llama master, no main

### SituaciÃ³n

Configuramos el workflow de CI/CD. Hicimos push. El pipeline no se ejecutÃ³.

### El error

No habÃ­a error visible. Simplemente no pasaba nada.

### Â¿Por quÃ© pasÃ³?

El workflow estaba configurado para `main`:

```yaml
on:
  push:
    branches: [main]  # â† Incorrecto
```

Pero nuestro repo usa `master` (el nombre histÃ³rico default de Git).

### CÃ³mo lo resolvimos

Cambiamos todas las referencias de `main` a `master`:

```yaml
on:
  push:
    branches: [master]  # â† Correcto
```

Y en la condiciÃ³n del job de deploy:

```yaml
if: github.ref == 'refs/heads/master'  # â† Correcto
```

**Â¿QuÃ© aprendimos?**

- Siempre verificar la configuraciÃ³n contra tu repo real
- GitHub cambiÃ³ el default de `master` a `main` en 2020
- Repos viejos pueden usar `master`, nuevos usan `main`
- Leer los logs de Actions para ver por quÃ© no se ejecutÃ³

---

## Problema 4: ImagePullBackOff en Kubernetes

### SituaciÃ³n

Hicimos deploy. Los pods no arrancan.

### El error

```
kubectl get pods -n voting-app
NAME                        READY   STATUS             RESTARTS   AGE
frontend-abc123             0/1     ImagePullBackOff   0          2m
```

```
kubectl describe pod frontend-abc123 -n voting-app
Events:
  Failed to pull image "votingappdevacr.azurecr.io/azure-vote-front:latest":
  unauthorized: authentication required
```

### Â¿Por quÃ© pasÃ³?

AKS no tiene permisos para descargar imÃ¡genes del ACR.

### Proceso de debugging

1. **Verificar que la imagen existe**:
```bash
az acr repository show-tags --name votingappdevacr --repository azure-vote-front
# Resultado: ["abc123d", "latest"]  â† La imagen SÃ existe
```

2. **Verificar permisos**:
```bash
az role assignment list --scope /subscriptions/X/resourceGroups/Y/providers/Microsoft.ContainerRegistry/registries/votingappdevacr
# Resultado: No hay assignment para el AKS
```

3. **Problema encontrado**: El role assignment no se creÃ³.

### CÃ³mo lo resolvimos

Creamos el role assignment manualmente (porque Terraform no lo habÃ­a aplicado):

```bash
az role assignment create \
  --assignee [AKS_KUBELET_IDENTITY] \
  --role AcrPull \
  --scope [ACR_ID]
```

DespuÃ©s verificamos:
```bash
kubectl delete pod frontend-abc123 -n voting-app
# El Deployment crea uno nuevo automÃ¡ticamente
kubectl get pods -n voting-app
# STATUS: Running âœ…
```

**Â¿QuÃ© aprendimos?**

El flujo de debugging para ImagePullBackOff:
1. Â¿La imagen existe en el registry? (nombre correcto, tag correcto)
2. Â¿Tengo acceso al registry? (permisos, authentication)
3. Â¿La imagen estÃ¡ corrupta? (raro pero posible)

---

## Problema 5: Pod en CrashLoopBackOff

### SituaciÃ³n

El pod arranca pero se reinicia constantemente.

### El error

```
kubectl get pods -n voting-app
NAME                        READY   STATUS             RESTARTS   AGE
frontend-xyz789             0/1     CrashLoopBackOff   4          3m
```

### Proceso de debugging

1. **Ver logs del pod**:
```bash
kubectl logs frontend-xyz789 -n voting-app
# Error: Cannot connect to Redis at 'redis:6379'
```

2. **Verificar que Redis existe**:
```bash
kubectl get pods -n voting-app
# redis-abc123    1/1     Running
kubectl get svc -n voting-app
# redis          ClusterIP   10.0.1.5    6379/TCP
```

3. **El servicio existe, Â¿por quÃ© no conecta?**

4. **Verificar DNS**:
```bash
kubectl run debug --rm -it --image=busybox -- nslookup redis.voting-app.svc.cluster.local
# Returns: 10.0.1.5   â† DNS funciona
```

5. **Verificar conectividad**:
```bash
kubectl run debug --rm -it --image=busybox -- nc -zv redis.voting-app.svc.cluster.local 6379
# Connection refused  â† Problema encontrado!
```

6. **Verificar que Redis estÃ¡ respondiendo**:
```bash
kubectl logs redis-abc123 -n voting-app
# Error: permission denied, cannot write to /data
```

### Â¿Por quÃ© pasÃ³?

Redis no podÃ­a escribir en su volumen por problemas de permisos.

### CÃ³mo lo resolvimos

Agregamos security context al pod de Redis:

```yaml
securityContext:
  fsGroup: 1000
  runAsUser: 1000
```

**Â¿QuÃ© aprendimos?**

Debugging sistemÃ¡tico:
1. **Ver logs** del pod que falla
2. **Verificar dependencias** (Â¿Redis estÃ¡ corriendo?)
3. **Verificar red** (Â¿DNS resuelve? Â¿Puerto accesible?)
4. **Ver logs de dependencias** (Â¿Redis tiene errores?)

---

## Problema 6: Federated Credential no matchea

### SituaciÃ³n

Configuramos OIDC. El workflow falla en Azure Login.

### El error

```
Error: AADSTS700212: No matching federated identity record found for presented assertion
```

### Â¿Por quÃ© pasÃ³?

El "subject" del token de GitHub no coincide con lo configurado en Azure.

El error tÃ­pico: configuramos para `main` pero el repo usa `master`.

### CÃ³mo lo resolvimos

1. Ver quÃ© subject envÃ­a GitHub:
```
repo:danmatgo/azure-voting-app-redis:ref:refs/heads/master
```

2. Ver quÃ© tenemos configurado en Azure:
```bash
az ad app federated-credential list --id $APP_ID
# subject: repo:danmatgo/azure-voting-app-redis:ref:refs/heads/main  â† MAL
```

3. Actualizar al subject correcto:
```bash
az ad app federated-credential delete --id $APP_ID --federated-credential-id "github-main"
az ad app federated-credential create --id $APP_ID --parameters '{
  "name": "github-master",
  "subject": "repo:danmatgo/azure-voting-app-redis:ref:refs/heads/master"
}'
```

**Â¿QuÃ© aprendimos?**

El subject DEBE coincidir EXACTAMENTE:
- Nombre del repo (case sensitive)
- Nombre de la rama (case sensitive)
- Tipo de evento (branch, environment, tag, etc.)

---

# ğŸ¤ CÃ“MO EXPLICAR TODO ESTO EN UNA ENTREVISTA

## Sobre tu background

> "He estado trabajando con infraestructura cloud y pipelines de CI/CD. Mi stack principal es Azure con Terraform para IaC, Kubernetes para orquestaciÃ³n, y GitHub Actions para automatizaciÃ³n. Me enfoco mucho en seguridad integrada desde el inicio del desarrollo."

## Sobre un proyecto reciente

> "ImplementÃ© un pipeline completo de CI/CD para una aplicaciÃ³n containerizada. La arquitectura usa AKS para el runtime, ACR como registry privado, y GitHub Actions con autenticaciÃ³n OIDC para evitar manejar secrets. IncluÃ­ escaneo de vulnerabilidades con Trivy antes de cada push al registry."

## Cuando pregunten sobre Terraform

> "Uso Terraform con remote backend en Azure Storage para el state, lo cual me da locking automÃ¡tico cuando trabajo en equipo. Estructuro el cÃ³digo con variables separadas por ambiente usando tfvars, asÃ­ el mismo cÃ³digo despliega a dev, staging y prod con configuraciones diferentes. Para seguridad, uso Managed Identity en vez de service principals con passwords."

## Cuando pregunten sobre Docker

> "Siempre uso multi-stage builds para minimizar el tamaÃ±o de imagen - he reducido imÃ¡genes de mÃ¡s de un GB a menos de 200MB. Los contenedores corren con usuario no-root por principio de least privilege. Pineo las versiones de todas las dependencias para garantizar reproducibilidad."

## Cuando pregunten sobre Kubernetes

> "Estructuro los manifests con Kustomize para manejar ambientes. Cada Deployment tiene liveness y readiness probes diferenciados - liveness para detectar procesos muertos, readiness para control de trÃ¡fico durante inicializaciÃ³n lenta. Uso HPA para escalar automÃ¡ticamente basado en CPU, con PDBs para garantizar disponibilidad durante mantenimiento."

## Cuando pregunten sobre CI/CD

> "Mi pipeline tÃ­pico es: build de imagen, escaneo de seguridad antes de push, y deploy a Kubernetes con Kustomize. Uso OIDC para autenticaciÃ³n con Azure - no hay passwords almacenados, solo tokens de corta duraciÃ³n. El deploy usa rolling updates para zero downtime."

## Cuando pregunten sobre un problema tÃ©cnico

> "Tuve un caso donde el escaneo de seguridad bloqueaba el pipeline por vulnerabilidades en la imagen base sin parche disponible. El dilema era: bloquear indefinidamente o aceptar riesgo. La soluciÃ³n fue configurar el escaneo como reporteo sin bloqueo, documentar la decisiÃ³n de riesgo con justificaciÃ³n, y crear un proceso de revisiÃ³n semanal. Cuando saliÃ³ el parche, lo aplicamos inmediatamente."

## Cuando pregunten sobre seguridad

> "Implemento shift-left security: escaneo de contenedores antes de push, anÃ¡lisis estÃ¡tico de cÃ³digo, y Dependabot para dependencias. En Kubernetes uso Network Policies para microsegmentaciÃ³n - por ejemplo, solo ciertos pods pueden hablar con la base de datos. TambiÃ©n aplico Pod Security Standards para evitar contenedores privilegiados."

---

# âœ… CHECKLIST FINAL DE CONOCIMIENTO

Para cada tema, pregÃºntate: Â¿Puedo explicar el por quÃ©, no solo el cÃ³mo?

## Terraform
- [ ] Â¿Por quÃ© usar remote backend?
- [ ] Â¿CuÃ¡l es la diferencia entre variables y locals?
- [ ] Â¿Por quÃ© Managed Identity en vez de service principal con password?
- [ ] Â¿QuÃ© es el state locking y por quÃ© importa?

## Docker
- [ ] Â¿Por quÃ© multi-stage build?
- [ ] Â¿Por quÃ© usuario no-root?
- [ ] Â¿Por quÃ© copiar requirements.txt antes que el cÃ³digo?
- [ ] Â¿CuÃ¡l es la diferencia entre ENTRYPOINT y CMD?

## Kubernetes
- [ ] Â¿CuÃ¡l es la diferencia entre Pod, Deployment y ReplicaSet?
- [ ] Â¿CuÃ¡ndo usar cada tipo de Service?
- [ ] Â¿CuÃ¡l es la diferencia entre liveness y readiness probes?
- [ ] Â¿QuÃ© son requests vs limits?
- [ ] Â¿Para quÃ© sirve un PodDisruptionBudget?

## CI/CD
- [ ] Â¿Por quÃ© OIDC es mejor que passwords en secrets?
- [ ] Â¿Por quÃ© escanear antes de push, no despuÃ©s?
- [ ] Â¿CÃ³mo fluye un cambio desde commit hasta producciÃ³n?

## DevSecOps
- [ ] Â¿QuÃ© significa shift-left security?
- [ ] Â¿QuÃ© detecta Trivy vs CodeQL vs Dependabot?
- [ ] Â¿Por quÃ© usar Network Policies?

---

# ğŸ“ ARCHIVOS CREADOS EN ESTA GUÃA

```
docs/
â”œâ”€â”€ MASTER_GUIDE_PART1.md    # Intro + Terraform bÃ¡sico
â”œâ”€â”€ MASTER_GUIDE_PART2.md    # Terraform red/AKS + Docker
â”œâ”€â”€ MASTER_GUIDE_PART3.md    # Kubernetes profundo
â”œâ”€â”€ MASTER_GUIDE_PART4.md    # Kustomize, CI/CD, DevSecOps
â””â”€â”€ MASTER_GUIDE_PART5.md    # Problemas + CÃ³mo explicar (este archivo)
```

---

**Recuerda**: En una entrevista tÃ©cnica, lo que buscan es:
1. Que entiendas los CONCEPTOS, no solo los comandos
2. Que puedas explicar el POR QUÃ‰ de las decisiones
3. Que hayas resuelto problemas reales
4. Que puedas comunicar claramente

Â¡Buena suerte! ğŸš€
